<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="portfolio" />
    <meta name="googlebot" content="noindex" />
    <meta name="google" content="sitelinkssearchbox" />
    <meta
      name="keywords"
      content="Animation,web development,Interactive Media"
    />
    <title>Portfolio</title>
    <link rel="stylesheet" href="styles.css" />
    <script src="https://cdn.lordicon.com/bhenfmcm.js"></script>
    <script
      src="https://kit.fontawesome.com/41822cedf2.js"
      crossorigin="anonymous"
    ></script>
  </head>
  <body>
    <header>
      <nav id="header"></nav>
    </header>

    <h1 id="titles" class="titles">Essays</h1>
    <h1 id="titles" class="titles">Assignment 2 Essay</h1>
    <article class="paragraphText" class="h-feed">
      <h2 class="smallerTitles" class="p-summary">
        Case study: Candle Merchant https://www.thecandlemerchant.co.za/
      </h2>
      <p class="paraSpacing" class="e-content">
        Websites are structured using user interface (UI) and user experience
        (UX). Designers take careful considerations when creating each aspect of
        a website. They also look at how their decisions impact the decisions
        made by a user. I intend to evaluate the ethics of the Candle Merchant.
        This will be done by analysing how the design principles are implemented
        in this website.
      </p>
      <p class="paraSpacing" class="e-content">
        User interface design determines the usability of a “software product”
        (Thimbleby 1990: 1). Usability is determined by the effectiveness of a
        product (Thimbleby 1990: 2). There are certain standards and conventions
        that exist for these software products. Conventions have a predetermined
        effectiveness aspect to them, and creators are encouraged to utilise
        them. Certain practices are repeated, thus they become conventions.
        Creators with similar intentions collaborate and adopt these practices
        (Mailloux 2015: 399). Users become accustomed to these conventions, and
        it forms the basis of their understanding for interacting with these
        products (Mailloux 2015: 400). The content of a product is what leads a
        user to a particular website. An example is the user searching “candle
        supplier” on Google and the search engine shows multiple results for the
        user to click on. The way the content is presented to a user on a
        website is what determines if the user will continue exploring the site
        or “take their business elsewhere” (Cappel & Huang 2007: 117). Thus,
        products are created with the basic principles of user interface design
        in mind.
      </p>

      <p class="paraSpacing" class="e-content">
        An important design principle is consistent design (Uxpin 2020: 2). The
        Candle Merchant website shows consistency through the similar squared
        buttons and squared images used throughout the site. Content is also
        present in square blocks on this site. The Candle Merchant however lacks
        consistency in the feedback given to a user, when they hover their mouse
        over a purchasable item. The design is inconsistent as the image of the
        item changes sometimes. Another issue is that the image that it changes
        to is often misleading since the image changes to something completely
        different. An example of this is when the user hovers over the “Votive
        Glass Clear” item and the image change to a candle holder. This ties
        into the cognitive load design principle (Uxpin 2020: 4). The changed
        image affects the user's recall. This directly influences the
        users&apos; decision in purchasing the item since it becomes slightly
        unclear as to which item they&apos;re about to purchase. The image
        changing incorrectly is also an example of poor design because the UI is
        no longer invisible (Uxpin 2020: 3). The Candle Merchant thus requires
        the user&apos;s active attention. If the UI design was invisible, it
        would&apos;ve provided a seamless mediation between the user and the
        site resulting in a successful sale for the Candle Merchant.
      </p>
      <p class="paraSpacing" class="e-content">
        Accessibility is a principle of user interface design (Uxpin 2020: 2).
        Many users have disabilities that affect their usage of websites. This
        is why designers need to make their websites accessible. One of the ways
        this can be done is with the screen reader. Users that are visually
        impaired use the information provided by the screen reader to create a
        “mental model” of the website (Lawson, 2019). This is where semantic
        markup comes in, in terms of letting the users know which elements are
        in the header or nav section (Lawson, 2019). This helps the user
        orientate themselves which will create a positive user experience
      </p>
      <p class="paraSpacing" class="e-content">
        The Candle Merchant is not accessible using the screen reader. This is
        because the information is read based on hierarchy, not on sections. The
        user is unable to determine where they are on the site and therefore
        cannot use it properly. An example of this is that the larger text on
        the main image of the homepage is read before the options in the header.
        Another example is when the screen reader reaches the item section with
        images. The images have no description and are read as “one”, “two” and
        so on, until it reaches the end. Only after this are the prices of the
        items read. The cognitive load would be too much for a user with a
        disability since they cannot be expected to remember the item number and
        its corresponding price.
      </p>

      <p class="paraSpacing" class="e-content">
        Users with disabilities require assistive technology, however, it is
        expensive, thus users require more viable options such as screen readers
        (Allen & Kleinman & Lazar & Malarkey 2007:). This is why it is important
        for developers to take this into consideration when designing a website.
        Accessibility is also related to the flexibility of a website. The
        flexibility of a website speaks to its responsive design.
      </p>

      <p class="paraSpacing" class="e-content">
        Users access websites through different devices and the design needs to
        be responsive for it to be accessible. This is a user interface design
        principle (Uxpin 2020: 5). The Candle Merchant has a responsive design
        to a certain degree. The nav bar and the header are replaced with a
        burger button that displays the corresponding options when clicked. An
        example of poor responsive design is that the search bar on the homepage
        disappears when the screen is smaller. The homepage has one search bar.
        This is not consistent since all the other pages on the Candle Merchant
        have two search bars (one is in the header, and the other is on the left
        side of the screen). The search bar on any page other than the homepage
        goes to the bottom of the page for a smaller screen. This strays from
        convention and there is no clarity. This means that a user has no
        indication of how to proceed since they are unable to find the search
        bar. This is also an example of poor interface design since Clarity is a
        design principle (Uxpin 2020: 2). Another example of poor responsive
        design on the Candle Merchant is that text overlaps and cuts off on the
        homepage. The size of the text changes slightly but not enough to be
        readable for the user.
      </p>

      <p class="paraSpacing" class="e-content">
        Clarity and consistency are vital aspects that determine the usability
        of a website (Cappel & Huang 2007: 117). The Candle Merchant uses the
        web design convention of indicating the active page by highlighting the
        title in the header (Cappel & Huang 2007: 117). However, this is
        inconsistent since it does not update when the user opens a particular
        page (Gift Ideas) through a button on the homepage. Another interface
        option is the call to action (CTA) at the bottom of every page that
        urges the user to sign up (Goldberg 2023). This assists the user with
        what steps to follow now that they have reached the bottom of a page.
      </p>
      <p class="paraSpacing" class="e-content">
        Visual structure is an important design principle since it relates to
        consistent design (Uxpin 2020: 5). This makes the user familiar with how
        to proceed throughout their time on a site. There is a discrepancy in
        navigation on the Candle Merchant. There is a navigation bar at the top
        of the screen and on the left side of the screen. This side navigation
        bar is not on the homepage. There is also an issue with the lack of
        visual hierarchy on the Candle Merchant. This can be seen by the same
        font, size and weight of text that is used for the name of the item, the
        descriptions as well as disclaimers. This is poor design because the
        user&apos;s attention is not being directed anywhere in particular. This
        also increases the cognitive load on a user since they require more
        effort to find information (Goldberg 2023).
      </p>
      <p class="paraSpacing" class="e-content">
        All items that are interactable give feedback to a user when they hover
        their mouse over it except for one section of the homepage on the Candle
        Merchant. This section has buttons that are in the middle of the
        homepage and have a different design than every other button. These
        buttons have icons and a shadow they do not give the user any feedback
        when they hover over it. These buttons act as navigation options and are
        confusing to a user since the options on the header have the same
        function. Hick&apos;s law states that more options given to a user at a
        time increase the number of decisions that a user makes (Goldberg 2023).
        The user is not provided with a clear next step since they are presented
        with many options at any given point. Providing the user with a clear
        next step is a design principle and not following it negatively affects
        the interface (Uxpin 2020: 5).
      </p>

      <p class="paraSpacing" class="e-content">
        The design principles create the usability of interfaces on a website.
        This gives designers the ability to direct attention and cause users to
        take certain actions. This is where ethical concerns of design come in
        (Goldberg 2023). An ethical issue for the Candle Merchant is
        prioritising their goals over the needs of a user. This can be seen in
        the “Gift Ideas” pages. There are two dark UX patterns at play since the
        text above an image presents a deal to a user (“Gift ideas under R150”).
        However, when the user clicks on the item the prices are displayed
        incorrectly. The Candle Merchant “shows” the equation to the user
        stating that these two items in this package equal X amount of money.
        This however does not add up since there is a hidden cost that is added,
        and the user is unaware of this (Battles & Gray & Hoggatt & Kou & Toombs
        2018: 2). This is manipulative since the site seemingly discloses that
        only the sum of the two items results in the total price, but this is
        not true due to the hidden cost.
      </p>

      <p class="paraSpacing" class="e-content">
        Another dark UX pattern is that items have a price range rather than a
        fixed value. This is a dark UX pattern because product attributes affect
        user interaction (Foxx & Funches & Kim & Park 2012: 1584). Users have
        primary concerns that help them achieve their goals (Foxx & Funches &
        Kim & Park 2012: 1584). A very common concern is price saving. Users
        become bargain hunters and look for the best deals.
      </p>

      <p class="paraSpacing" class="e-content">
        The Candle Merchant overwhelms the user with many navigation options
        that have the same function throughout the site. They also make use of
        dark UX patterns that persuade the actions of a user in a way that
        benefits the Candle Merchant. It is evident that the design of this
        website was carefully constructed with usability in mind
      </p>

      <h2 class="smallerTitles">References:</h2>
      <p class="p-author">Thimbleby, H., 1990. User interface design. ACM.</p>
      <p class="p-author">
        Mailloux, S., 2015. Convention and context. New Literary History, 14(2),
        pp.399-407.
      </p>

      <p class="p-author">
        Cappel, J.J. & Huang, Z., 2007. A usability analysis of company
        websites. Journal of Computer Information Systems, 48(1), pp.117-123.
      </p>

      <p class="p-author">
        Uxpin. (2020). The Basic Principles of User Interface Design. The Basic
        Principles of User Interface Design (uxpin.com). 19 March 2023.
      </p>

      <p class="p-author">
        Lawson, Bruce. “How A Screen Reader User Accesses The Web: A Smashing
        Video.” Smashing Magazine,
        https://www.smashingmagazine.com/2019/02/accessibility-webinar .18 Feb.
        2019.
      </p>

      <p class="p-author">
        Allen, A. & Kleinman, J. & Lazar, J, & Malarkey, C., 2007. What
        frustrates screen reader users on the web: A study of 100 blind users.
        International Journal of human-computer interaction, 22(3), pp.247-269.
      </p>

      <p class="p-author">
        Goldberg, P. 2023. Interaction Design - IA, UI and UX, 16 March 2023.
        Lecture notes (WSOA3028A). University of the Witwatersrand, Johannesburg
      </p>
      <p class="p-author">
        Goldberg, P. 2023. Ethics of UX Practice, 6 April 2023. Lecture notes
        (WSOA3028A). University of the Witwatersrand, Johannesburg
      </p>
      <p class="p-author">
        Battles, B. & Gray, C.M. & Hoggatt, J. & Kou, Y & Toombs, A.L., 2018,
        April. The dark (patterns) side of UX design. In Proceedings of the 2018
        CHI conference on human factors in computing systems (pp. 1-14).
      </p>
      <p class="p-author">
        Foxx, W. & Funches, V.M. & Kim, E.Y., & Park, E.J., 2012. Apparel
        product attributes, web browsing, and e-impulse buying on shopping
        websites. Journal of business research, 65(11), pp.1583
      </p>
      <p class="p-author">
        The Candle Merchant. (2023) The Candle Merchant. Available at:
        https://www.thecandlemerchant.co.za/ (Accessed: 27 April 2023)
      </p>
    </article>
    <h1 id="titles" class="titles">Final Assessment Essay</h1>
    <section>
      <p></p>
      <article class="paragraphText" class="h-feed">
        <h2 class="smallerTitles" class="p-summary">
          Mitigating the risk of extinction from AI should be a global priority
          alongside other societal-scale risks such as pandemics and nuclear
          war.--the Impact of AI and algorithmic culture on the Internet.
        </h2>
        <p class="paraSpacing" class="e-content">
          Artificial Intelligence (AI) and algorithmic culture have impacted the
          internet and resulted in a bleak outcome. The “Statement on AI Risk”
          initiates the conversation on the potentially harmful effects of AI
          (CAIS, 2023). I intend to explore the effects of AI and algorithmic
          culture on the Internet through the lens of the Internet, Society and
          Design Justice. I will do this while focusing on the importance of
          including affected users in the design process.
        </p>
        <p class="paraSpacing" class="e-content">
          The “Statement on AI Risk” was released by the Centre for AI Safety
          (CAIS) and warns against the threat posed by AI (CAIS, 2023). The CAIS
          website outlines 8 possible risks of AI, these risks however warn
          against the future development of AI such as Power-Seeking Behaviour.
          Many have stated that this warning is “premature” and that the AI
          models of today should not be considered an existential risk (COLOMÉ,
          2023). This statement urges people to take their focus off the current
          AI models and this is deemed problematic (Paul, 2023). This is because
          it causes the harmful effects of AI today to become trivial in
          comparison. A possible suggestion for this statement is that it causes
          “politicians to spend their time discussing future doomsday
          scenarios”, this allows Big Tech Companies to flourish in their
          expansion of “big AI firms” (COLOMÉ, 2023). The plausibility of this
          is confirmed by the seemingly unfathomable nature of AI models which
          causes people in power, such as lawmakers and regulators, to turn to
          the “experts” (COLOMÉ, 2023).
        </p>

        <p class="paraSpacing" class="e-content">
          This “Statement on AI Risk” follows a manifesto released in March 2023
          that called for a halt in AI development (Paul, 2023). This statement
          however holds more weight than the manifesto due to the signatories.
          It was signed by industry leaders, the experts (Geofrrey Hinton, Sam
          Altman, Yoshua Bengio, Demis Hassabis, and Dario Amodei), to vocalize
          concerns about AI and calls for the generation of legislation for AI
          (COLOMÉ, 2023). This increases the seriousness of the “Statement on AI
          Risk”. According to the CAIS, it was vital for AI experts to sign the
          statement since it helped “overcome this obstacle” of discussing the
          risks of AI (CAIS, 2023).
        </p>
        <p class="paraSpacing" class="e-content">
          The CAIS defines AI risk as the ability of AI “to act autonomously to
          cause harm” (CAIS, 2023). The “harm” caused by AI is that it can be
          used to spread misinformation and maintain biases (CAIS, 2023). AI
          reflects biases present in the data used to construct it (Yarger &
          Cobb Payton & Neupane 2020: 2). Unequal access to the internet cause
          groups of people to be excluded from data collected since they are
          unable to participate (Kasapis, 2020). Thus, there are gaps in the
          data used for AI models which negatively impacts the internet. This
          draws attention away from the positive impacts that AI has had on the
          internet.
        </p>
        <p class="paraSpacing" class="e-content">
          The digital age calls for more efficient, less traditional, methods of
          getting things done. AI in many ways helps accomplish this and can be
          seen by AI&apos;s ability to sort through vast amounts of data. An
          example of this in practice is that AI models are used to support
          workforce development in the form of AI talent acquisition software
          (Yarger & Cobb Payton & Neupane 2020: 2). This is cause for concern
          because this software uses algorithms that are biased. These
          algorithms use data collected from the past and the issue with this is
          that some groups were “historically disadvantaged” (Yarger & Cobb
          Payton & Neupane 2020: 2). This brings ups questions on the equity of
          algorithms used in talent acquisition software.
        </p>

        <p class="paraSpacing" class="e-content">
          The paper by Yarger, Cobb Payton and Neupane looks at “Algorithmic
          Equity in the Hiring of Underrepresented IT Job Candidates”. Diversity
          in the technology industry remains static due to “employee turnover”
          (Yarger & Cobb Payton & Neupane 2020: 3). Women and underrepresented
          minorities face a blockade of challenges when entering tech fields
          such as screening biases, companies in recent years have attempted to
          diversify the tech industry. Despite these attempts minorities and
          women who manage to get careers in technology eventually leave, and
          this system could be described as “a revolving door” (Yarger & Cobb
          Payton & Neupane 2020: 3). This happens because the entire pipeline
          contains a network of biases that are woven into it and to change it
          would cost the industry “over 16 billion US dollars” (Yarger & Cobb
          Payton & Neupane 2020: 3). For this reason, the data collected on the
          tech workforce is skewed in that it lacks diversity.
        </p>

        <p class="paraSpacing" class="e-content">
          AI is unable to discern between a candidate&apos;s ability to fulfil
          the job requirements and the pattern in employee records such as race
          and gender. AI is given the very important task of sorting through
          candidates; this was noted in 2016 when it was documented that these
          algorithms “weeded out” 72% of resumes “before a human ever saw them”
          (Yarger & Cobb Payton & Neupane 2020: 3). This presents a significant
          issue since it affects people&apos;s livelihoods and perpetuates
          biases. Beyond the employment records data, there are other sets of
          data used by these algorithms that inform the AI talent acquisition
          software. These other data sets however place marginalized groups at a
          disadvantage, this is due to a lack of representation (Yarger & Cobb
          Payton & Neupane 2020: 3). Thus, the data used by AI is flawed and
          this impacts its selection process of job candidates. This gap in data
          is a consequence of digital inequality and unequal access to the
          Internet (Daniolou, 2020).
        </p>

        <p class="paraSpacing" class="e-content"></p>
        <p class="paraSpacing" class="e-content">
          Digitalisation is happening at an unequal rate, and this affects which
          groups of people can contribute to the Internet (Kositany-Buckner,
          2022) (Kasapis, 2020). This widens the digital divide which
          “exacerbates existing inequalities” and this affects marginalised
          groups (Tataki & Glynos, 2020). Due to their inability to contribute,
          marginalised groups are excluded from data sets. This is an issue that
          becomes more prominent when data that excludes them is used to create
          products for them. This directly goes against the design of The Design
          Justice Network Principles since the lived experience of a
          marginalised group is overlooked and products are designed without
          being community-led or controlled (Design Justice Network, 2015).
        </p>
        <p class="paraSpacing" class="e-content">
          A study was conducted that “measured how people from marginalized
          racial and socioeconomic groups perceived algorithmic fairness”, which
          can be seen as utilisation of The Design Justice Network Principals
          (Yarger & Cobb Payton & Neupane 2020: 3) (Design Justice Network,
          2015). The results of the study helped designers in changing the
          algorithm used by the AI talent acquisition software (Yarger & Cobb
          Payton & Neupane 2020: 3). Designers, in this case, centred people who
          are usually marginalized, and this is important because they are the
          ones who are directly affected by these algorithms (Costanza-Chock
          2020: 7). The overall results of this process, of including diverse
          people, proved to be profitable and innovative for companies (Yarger &
          Cobb Payton & Neupane 2020: 4). While this attempt to rectify the
          injustices of algorithms is successful and does it in a manner that
          changes the algorithm, there are other methods that succumb to the
          biased system of an algorithm.
        </p>

        <p class="paraSpacing" class="e-content"></p>

        <p class="paraSpacing" class="e-content">
          There have been a few companies that have implemented approaches to
          mitigate bias in job recruitment software such as Blendoor and Gas
          Jumper. The paper by Yarger, Cobb Payton and Neupane commends these
          companies for their innovative use of intentional design justice. Gas
          Jumper is used by IT companies to “test” their applicants and they are
          evaluated by their skills (Yarger & Cobb Payton & Neupane 2020: 4).
          However, the company Blendoor takes an arguably backward approach.
          This is because the company “removes personal identifying information
          from a resume”, this includes the applicant's name, hobby and even the
          name of the institution which they studied (Yarger & Cobb Payton &
          Neupane 2020: 4). This information could indicate a person&apos;s
          marital status, gender and race and this system “blendorizes” the
          profile of candidates. This uses “resume whitening” which “adapts to
          anticipated discrimination”. This means that a candidate must strip
          away their identity in some sense, in the hopes of being hired. This
          process in its entirety could have been avoided if the AI talent
          acquisition software, fostered equality, and the inclusion of
          marginalised individuals. The method used by the Blendoor company
          could be seen as part of the problem. Despite their “good” intentions,
          as spoken about earlier, the entire employment pipeline of technology
          jobs is littered with biases and Blendoor succumbs their users to
          this. Contrary to what many believe the issues with AI are less
          technical and are more related to social and political systems
          (McDonald & Massey& Hamidi 2021: 4).
        </p>

        <p class="paraSpacing" class="e-content">
          Algorithms mirror social and historical discriminatory behaviour due
          to their use of predictive models (Birhane. & Cummins 2019:). This
          indicates the need for a conceptual understanding from creators. It is
          the responsibility of a designer to be aware of systems of power and
          social politics as well as their impact on people. The designer is
          required to take this knowledge into account when creating software
          for AI since the “harms from AI” are the result of “the acts of
          people” (Paul, 2023) (McDonald & Massey& Hamidi 2021: 4). Designers
          have opted to imagine possible scenarios of users to identify
          challenges marginalised groups may face (McDonald & Massey& Hamidi
          2021: 4). This reiterates the value of centring a user in the design
          process.
        </p>
        <p class="paraSpacing" class="e-content">
          The paper by McDonald, Massey and Hamidi “AI-Enhanced Adaptive
          Assistive Technologies: Methods for AI Design Justice” takes an
          intersectional approach to collaborative design (McDonald & Massey&
          Hamidi 2021: 3). AI has benefitted people with disabilities, however
          each person with a disability requires varying degrees of assistance
          (McDonald & Massey& Hamidi 2021: 4). Hence the word “adaptive” in
          AI-enhanced Adaptive Assistive Technologies (AATs). This requires data
          to be collected from users, this presents a privacy risk since the
          data could potentially be sold to advertisers and insurance companies
          (McDonald & Massey& Hamidi 2021: 4). Since AI is trained on data from
          AATs, they can determine if someone has a disability based on their
          social media presence. Advertisers and insurance companies “need” this
          data to market their products to specific users, this places a lot of
          value on the captured data. That capturing and sale of this data in
          the hands of the designer and speak to their morality. Some designers
          recognise this “power” and choose to focus on their impact on a
          community which is in line with 3rd principle of the Design Justice
          Network (The Design Justice Network, 2015).
        </p>
        <p class="paraSpacing" class="e-content">
          Another principle of the design justice network is looked at in the
          paper by McDonald, Massey and Hamidi who state that “everyone is an
          expert based on their own lived experience” (The Design Justice
          Network, 2015). Designers and policymakers have “normative perceptions
          of vulnerability” thus any attempts to create without input from
          marginalised groups is ineffective (McDonald & Massey& Hamidi 2021:
          4). A method used to connect the designer to the experience of a user
          is called “Empathy Exercises”, this entails designers taking on the
          “lived experience” of the user (McDonald & Massey& Hamidi 2021: 7).
          However, this may have a “paradoxical advantage” and it may feel very
          real to the designer causing them to distance them self from the
          experience. This paper also discusses the difference between help and
          support which is very eye-opening for me as a designer. Help comes
          from a place of empathy based on a designer&apos;s perception of an
          experience and support shows compassion and appreciation of the user's
          experience (McDonald & Massey& Hamidi 2021: 7).
        </p>
        <p class="paraSpacing" class="e-content">
          AI can potentially harm many through their reiteration of biases. This
          however can be combated by the efforts of a designer such as taking an
          intersectional approach. Designers can also choose to widen the
          spectrum of data that they use to create algorithms. This diversifies
          algorithms and influences the impact of AI on the internet in a
          positive manner.
        </p>

        <h2 class="smallerTitles">References:</h2>
        <p class="p-author">
          CAIS, 2023. Centre for AI Safety. Statement on AI Risk. [Online].
          Available at: https://www.safe.ai/statement-on-ai-risk. [Accessed 20
          June 2023].
        </p>
        <p class="p-author">
          COLOMÉ, J. P., 2023. ELPAIS. Why are the people who pushed for
          artificial intelligence now signing so many doomsday manifestos?
          [Online].Available at:
          https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html.
          [Accessed 20 June 2023].
        </p>

        <p class="p-author">
          Daniolou, C., 2020. Institute for Internet & the Just Society.The Need
          for Global Internet Connectivity. [Online] Available at:
          https://www.internetjustsociety.org/the-need-for-global-internet-connectivity
          [Accessed 20 June 2023].
        </p>

        <p class="p-author">
          Kasapis, S., 2020. Institute for Internet & the Just Society.Internet
          Access is a Fundamental Right. Especially, Amidst a Pandemic. [Online]
          Available at:
          https://www.internetjustsociety.org/internet-access-is-a-fundamental-rights-especially-amidst-a-pandemic
          [Accessed 20 June 2023].
        </p>

        <p class="p-author">
          Kositany-Buckner, C., 2022. Digital Inclusion. [Online] Available at:
          https://www.internetjustsociety.org/digitalinclusion [Accessed 20 June
          2023].
        </p>

        <p class="p-author">
          Magnoni, S., 2019. World Economic Forum. [Online] Available at:
          https://www.weforum.org/agenda/2019/04/digital-equality-interview-nanjira-sambuli/
          [Accessed 6 June 2023].
        </p>

        <p class="p-author">
          Network, T. D. J., 2015. The Design Justice Network Principles.
          [Online] Available at: https://designjustice.org/ [Accessed 20 June
          2023].
        </p>
        <p class="p-author">
          Paul, A., 2023. Popular Science. Big Tech&apos;s latest AI doomsday
          warning might be more of the same hype. [Online] Available at:
          https://www.popsci.com/technology/ai-warning-critics/ [Accessed 20
          June 2023].
        </p>
        <p class="p-author">
          Paul, K., 2023. The Guardian.Robot takeover? Not quite. Here&apos;s
          what AI doomsday would look like. [Online] Available at:
          https://www.theguardian.com/technology/2023/jun/03/ai-danger-doomsday-chatgpt-robots-fears.
          [Accessed 20 June 2023].
        </p>
        <p class="p-author">
          Tataki, M. & Glynos, D., 2020. Institute for Internet & the Just
          Society. Digital Divide Widens. [Online]. Available at:
          https://www.internetjustsociety.org/digital-divide-widens. [Accessed
          20 June 2023].
        </p>
        <p class="p-author">
          Vallance, C., 2023. BBC.Artificial intelligence could lead to
          extinction, experts warn. [Online]. Available at:
          https://www.bbc.com/news/uk-65746524. [Accessed 20 June 2023].
        </p>
        <p class="p-author">
          Buolamwini, J. & Gebru, T., 2018, January. Gender shades:
          Intersectional accuracy disparities in commercial gender
          classification. In Conference on fairness, accountability, and
          transparency (pp. 77-91). PMLR.
        </p>
        <p class="p-author">
          Birhane, A. & Cummins, F., 2019. Algorithmic injustices: Towards a
          relational ethics. arXiv preprint arXiv:1912.07376.
        </p>
        <p class="p-author">
          Yarger, L., & Cobb Payton, F. & Neupane, B., 2020. Algorithmic equity
          in the hiring of underrepresented IT job candidates. Online
          information review, 44(2), pp.383-395.
        </p>
        <p class="p-author">
          McDonald, N., & Massey, A.K. & Hamidi, F., 2021. AI-Enhanced Adaptive
          Assistive Technologies: Methods for AI Design Justice. IEEE Data Eng.
          Bull., 44(4), pp.3-13.
        </p>
        <p class="p-author">
          Ugwudike, P., 2022. Predictive algorithms in justice systems and the
          limits of tech-reformism. International Journal for Crime, Justice and
          Social Democracy, 11(1), pp.85-99.
        </p>
        <p class="p-author">
          Costanza-Chock, S., 2020. Introduction: # TravelingWhileTrans, Design
          Justice, and Escape from the Matrix of Domination. Design Justice, 1.
        </p>
      </article>
    </section>
  </body>
  <footer></footer>
  <script src="app.js"></script>
</html>
